---
phase: 04-video-audio-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/types/campaign.ts
  - src/lib/db/schema.ts
  - src/lib/ai/runway.ts
  - src/lib/ai/elevenlabs.ts
  - src/lib/ai/kling.ts
  - src/lib/ai/heygen.ts
  - src/lib/constants/video-providers.ts
  - src/lib/ai/provider-health.ts
  - package.json
autonomous: true
user_setup:
  - service: runway
    why: "Runway Gen-4 cinematic video generation"
    env_vars:
      - name: RUNWAYML_API_SECRET
        source: "Runway Dashboard -> API Keys (https://app.runwayml.com)"
  - service: elevenlabs
    why: "Japanese voiceover TTS generation"
    env_vars:
      - name: ELEVENLABS_API_KEY
        source: "ElevenLabs Dashboard -> API Keys (https://elevenlabs.io/app/settings/api-keys)"
      - name: ELEVENLABS_VOICE_ID_JP_FEMALE
        source: "ElevenLabs Dashboard -> Voices (pick a Japanese female voice ID)"
      - name: ELEVENLABS_VOICE_ID_JP_MALE
        source: "ElevenLabs Dashboard -> Voices (pick a Japanese male voice ID)"
  - service: fal.ai (Kling proxy)
    why: "Kling video ad generation via fal.ai (simpler auth than direct Kling API)"
    env_vars:
      - name: FAL_KEY
        source: "fal.ai Dashboard -> API Keys (https://fal.ai/dashboard/keys)"
  - service: heygen
    why: "AI avatar presenter video generation"
    env_vars:
      - name: HEYGEN_API_KEY
        source: "HeyGen Dashboard -> API Settings (https://app.heygen.com/settings)"
      - name: HEYGEN_DEFAULT_AVATAR_ID
        source: "HeyGen Dashboard -> Avatars (select a JP-presenting avatar)"
      - name: HEYGEN_JP_VOICE_ID
        source: "HeyGen Dashboard -> Voices (select a Japanese voice)"

must_haves:
  truths:
    - "CampaignProgress type includes voiceoverStatus, videoStatus, and avatarStatus fields"
    - "Each video/audio provider has a typed client module with submit-poll-retrieve pattern"
    - "Provider fallback mappings and cost constants are centrally defined"
    - "Circuit breaker pattern tracks provider health for fallback routing decisions"
  artifacts:
    - path: "src/lib/ai/runway.ts"
      provides: "Runway Gen-4 image-to-video client"
      exports: ["generateCinematicVideo"]
    - path: "src/lib/ai/elevenlabs.ts"
      provides: "ElevenLabs Japanese TTS client"
      exports: ["generateJapaneseVoiceover"]
    - path: "src/lib/ai/kling.ts"
      provides: "Kling video ad generation client via fal.ai"
      exports: ["generateKlingVideo"]
    - path: "src/lib/ai/heygen.ts"
      provides: "HeyGen avatar video generation client"
      exports: ["generateAvatarVideo"]
    - path: "src/lib/constants/video-providers.ts"
      provides: "Provider configs, fallback mappings, cost tables, aspect ratio mappings"
      exports: ["VIDEO_PROVIDERS", "FALLBACK_MAP", "PLATFORM_ASPECT_RATIOS"]
    - path: "src/lib/ai/provider-health.ts"
      provides: "Circuit breaker pattern for provider health tracking"
      exports: ["ProviderHealthTracker"]
  key_links:
    - from: "src/lib/ai/runway.ts"
      to: "@runwayml/sdk"
      via: "SDK import"
      pattern: "import RunwayML from"
    - from: "src/lib/ai/elevenlabs.ts"
      to: "@elevenlabs/elevenlabs-js"
      via: "SDK import"
      pattern: "import.*ElevenLabsClient"
    - from: "src/lib/ai/kling.ts"
      to: "fal.ai REST API"
      via: "fetch calls to queue.fal.run"
      pattern: "queue\\.fal\\.run"
    - from: "src/lib/ai/heygen.ts"
      to: "HeyGen REST API"
      via: "fetch calls to api.heygen.com"
      pattern: "api\\.heygen\\.com"
    - from: "src/types/campaign.ts"
      to: "src/lib/db/schema.ts"
      via: "CampaignProgress type sync"
      pattern: "voiceoverStatus.*videoStatus.*avatarStatus"
---

<objective>
Create the foundational provider client modules, type extensions, and configuration constants for the video/audio pipeline.

Purpose: Establish typed, testable client modules for all four video/audio providers (Runway, ElevenLabs, Kling via fal.ai, HeyGen) alongside extended campaign types and provider configuration. These modules will be consumed by the pipeline orchestration layer (04-02) and the n8n workflow Code nodes.

Output: 4 provider client modules, extended CampaignProgress type, video provider constants, provider health tracker
</objective>

<execution_context>
@/Users/hani/.claude/get-shit-done/workflows/execute-plan.md
@/Users/hani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-video-audio-pipeline/04-RESEARCH.md
@src/types/campaign.ts
@src/lib/db/schema.ts
@src/lib/ai/flux.ts
@src/lib/ai/claude.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install SDKs, extend types, create provider constants</name>
  <files>
    package.json
    src/types/campaign.ts
    src/lib/db/schema.ts
    src/lib/constants/video-providers.ts
    src/lib/ai/provider-health.ts
  </files>
  <action>
    1. Install the two official SDKs:
       ```
       pnpm add @runwayml/sdk @elevenlabs/elevenlabs-js
       ```

    2. Extend `CampaignProgress` in BOTH `src/types/campaign.ts` AND `src/lib/db/schema.ts` (they must stay in sync):
       - Add `voiceoverStatus?: "pending" | "generating" | "complete" | "failed" | "skipped"`
       - Add `videoStatus?: "pending" | "generating" | "complete" | "failed" | "skipped"`
       - Add `avatarStatus?: "pending" | "generating" | "complete" | "failed" | "skipped"`
       Note: "skipped" is for when the user's brief doesn't include video platforms or avatar.

    3. Create `src/lib/constants/video-providers.ts` with:
       - `VIDEO_PROVIDERS` object: provider configs with id, name, costPerSecond, maxDuration, supportedAspectRatios, authType
         - kling: { id: "kling", name: "Kling", costPerSecond: 0.07, maxDuration: 10, supportedAspectRatios: ["16:9", "9:16", "1:1"], authType: "api-key" }
         - runway: { id: "runway", name: "Runway Gen-4", costPerSecond: 0.05, maxDuration: 10, supportedAspectRatios: ["1920:1080", "1080:1920", "960:960"], authType: "sdk" }
         - elevenlabs: { id: "elevenlabs", name: "ElevenLabs", costPerChar: 0.00033, authType: "sdk" }
         - heygen: { id: "heygen", name: "HeyGen", costPerMinute: 0.50, maxDuration: 60, authType: "api-key" }
       - `FALLBACK_MAP`: { kling: "runway", runway: "kling" } (HeyGen has no fallback -- unique capability)
       - `PLATFORM_ASPECT_RATIOS`: map from platform IDs to required video aspect ratios
         - youtube: ["16:9"]
         - instagram_feed: ["1:1"]
         - instagram_story: ["9:16"]
         - tiktok: ["9:16"]
         - line: ["1:1"]
         - x_twitter: ["16:9"]
       - `GENERATION_ORDER`: array defining pipeline order: ["voiceover", "video", "cinematic", "avatar"]
       - Export TypeScript interfaces: `VideoProvider`, `FallbackMap`, `PlatformAspectRatios`

    4. Create `src/lib/ai/provider-health.ts` with:
       - `ProviderHealthTracker` class (singleton pattern like BudouX parser):
         - Private `healthMap: Map<string, { consecutiveFailures: number, lastFailure: Date | null, circuitOpen: boolean }>`
         - `recordSuccess(providerId: string)`: reset consecutiveFailures, close circuit
         - `recordFailure(providerId: string)`: increment failures, open circuit if >= 3
         - `shouldUseProvider(providerId: string)`: returns true if circuit closed OR cooldown (5 min) has elapsed
         - `getHealth(providerId: string)`: returns current health state
       - Export singleton: `export const providerHealth = new ProviderHealthTracker()`
       - This is an in-memory tracker (not persisted to DB). Resets on server restart, which is acceptable for MVP.
  </action>
  <verify>
    `pnpm build` passes. Check that `@runwayml/sdk` and `@elevenlabs/elevenlabs-js` appear in package.json dependencies. Verify CampaignProgress in both schema.ts and campaign.ts include the three new optional fields.
  </verify>
  <done>
    SDKs installed. CampaignProgress extended with voiceoverStatus, videoStatus, avatarStatus. VIDEO_PROVIDERS, FALLBACK_MAP, PLATFORM_ASPECT_RATIOS, and GENERATION_ORDER exported from constants. ProviderHealthTracker singleton exported with circuit breaker logic.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create provider client modules (Runway, ElevenLabs, Kling, HeyGen)</name>
  <files>
    src/lib/ai/runway.ts
    src/lib/ai/elevenlabs.ts
    src/lib/ai/kling.ts
    src/lib/ai/heygen.ts
  </files>
  <action>
    Create four provider client modules following the established pattern in `src/lib/ai/flux.ts` (async submit-poll-retrieve). Each module exports a single generation function.

    1. **`src/lib/ai/runway.ts`** -- Runway Gen-4 cinematic video:
       ```typescript
       import RunwayML from "@runwayml/sdk"
       ```
       - Export `generateCinematicVideo(imageUrl: string, promptText: string, options?: { ratio?: string, duration?: number }): Promise<string>`
       - Initialize RunwayML client with `process.env.RUNWAYML_API_SECRET`
       - Call `client.imageToVideo.create({ model: "gen4_turbo", promptImage: imageUrl, promptText, ratio: options.ratio ?? "1920:1080", duration: options.duration ?? 10 })`
       - Poll `client.tasks.retrieve(task.id)` every 5 seconds, max 60 attempts (5 min timeout)
       - Return video URL from `result.output[0]` on SUCCEEDED
       - Throw descriptive error on FAILED or timeout
       - Log poll attempts with `console.log("Runway poll attempt ${attempts}/${maxAttempts} for task ${task.id}")`

    2. **`src/lib/ai/elevenlabs.ts`** -- Japanese TTS (synchronous, no polling):
       ```typescript
       import { ElevenLabsClient } from "@elevenlabs/elevenlabs-js"
       ```
       - Export `generateJapaneseVoiceover(text: string, voiceId: string, options?: { modelId?: string }): Promise<{ buffer: Buffer, durationEstimate: number }>`
       - Initialize ElevenLabsClient with `process.env.ELEVENLABS_API_KEY`
       - Call `client.textToSpeech.convert(voiceId, { text, modelId: options.modelId ?? "eleven_multilingual_v2", outputFormat: "mp3_44100_128", languageCode: "ja" })`
       - Convert the returned ReadableStream to Buffer by reading chunks
       - Estimate duration: `Math.round(buffer.length / 16000)` (MP3 128kbps ~ 16KB/sec)
       - Return `{ buffer, durationEstimate }`
       - Note in JSDoc: `apply_language_text_normalization` omitted to avoid latency; enable if intonation issues observed

    3. **`src/lib/ai/kling.ts`** -- Kling via fal.ai proxy:
       - Export `generateKlingVideo(prompt: string, options?: { imageUrl?: string, duration?: 5 | 10, aspectRatio?: "16:9" | "9:16" | "1:1", withAudio?: boolean }): Promise<string>`
       - Use native `fetch` to call fal.ai REST API:
         - Base URL: `https://queue.fal.run`
         - Endpoint: `fal-ai/kling-video/v2.6/pro/image-to-video` if imageUrl provided, else `fal-ai/kling-video/v2.6/pro/text-to-video`
         - Auth header: `Authorization: Key ${process.env.FAL_KEY}`
         - Body: `{ prompt, image_url?, duration: String(duration ?? 5), aspect_ratio: aspectRatio ?? "16:9", enable_audio?: true }`
       - Submit returns `{ request_id }`. Poll status endpoint every 5 seconds, max 60 attempts.
       - On COMPLETED, fetch result and return `result.video?.url ?? result.output?.url`
       - Throw on FAILED or timeout

    4. **`src/lib/ai/heygen.ts`** -- HeyGen avatar video:
       - Export `generateAvatarVideo(params: { avatarId: string, voiceId: string, script: string, dimension?: { width: number, height: number } }): Promise<string>`
       - Use native `fetch` to call HeyGen REST API:
         - Submit: `POST https://api.heygen.com/v2/video/generate` with `X-Api-Key: ${process.env.HEYGEN_API_KEY}`
         - Body: `{ video_inputs: [{ character: { type: "avatar", avatar_id, avatar_style: "normal" }, voice: { type: "text", voice_id, input_text: script, speed: 1.0 } }], dimension: dimension ?? { width: 1920, height: 1080 } }`
       - Extract `data.video_id` from response
       - Poll: `GET https://api.heygen.com/v1/video_status.get?video_id=${videoId}` every 5 seconds, max 120 attempts (10 min timeout -- avatar videos can take 2-5 min)
       - Return `statusData.data.video_url` on completed
       - Throw on failed or timeout

    **Common patterns across all modules:**
    - Each function checks its required env var and throws a clear error if missing (e.g., "RUNWAYML_API_SECRET is not set")
    - Poll loops use `await new Promise(resolve => setTimeout(resolve, 5000))` for 5-second intervals
    - All functions include JSDoc with parameter descriptions and usage notes
    - No direct database interaction -- these are pure API client functions
  </action>
  <verify>
    `pnpm build` passes. Each of the 4 files exists and exports its generation function. Grep for the expected function signatures: `generateCinematicVideo`, `generateJapaneseVoiceover`, `generateKlingVideo`, `generateAvatarVideo`.
  </verify>
  <done>
    Four provider client modules created with typed submit-poll-retrieve patterns. Runway uses official SDK, ElevenLabs uses official SDK, Kling uses fal.ai REST proxy, HeyGen uses REST API. Each module exports a single async generation function returning either a URL (video) or Buffer+duration (audio).
  </done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with no type errors
2. `@runwayml/sdk` and `@elevenlabs/elevenlabs-js` in package.json dependencies
3. CampaignProgress in schema.ts has voiceoverStatus, videoStatus, avatarStatus
4. CampaignProgress in campaign.ts mirrors schema.ts exactly
5. All 4 provider modules export their generation functions
6. video-providers.ts exports VIDEO_PROVIDERS, FALLBACK_MAP, PLATFORM_ASPECT_RATIOS, GENERATION_ORDER
7. provider-health.ts exports ProviderHealthTracker singleton with circuit breaker methods
</verification>

<success_criteria>
- All provider client modules compile and export typed async generation functions
- CampaignProgress type extended for video/audio stages in both type definition locations
- Provider constants centrally define costs, fallback mappings, and platform-to-aspect-ratio mappings
- Circuit breaker tracker ready for fallback routing decisions
- SDKs installed and importable
</success_criteria>

<output>
After completion, create `.planning/phases/04-video-audio-pipeline/04-01-SUMMARY.md`
</output>
