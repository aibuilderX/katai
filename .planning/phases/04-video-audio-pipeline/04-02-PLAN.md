---
phase: 04-video-audio-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/app/api/webhooks/n8n/route.ts
  - src/app/api/campaigns/route.ts
  - src/lib/ai/video-pipeline.ts
  - src/lib/platforms/zip-packager.ts
autonomous: true

must_haves:
  truths:
    - "n8n webhook handler accepts video and audio asset payloads and persists them to the assets table"
    - "Provider-generated video/audio URLs are downloaded to Supabase Storage before storing the storage key"
    - "Campaign pipeline generates voiceover, video ads, and cinematic video in correct order (cheapest first)"
    - "Video and audio assets appear in the assets table with correct type, metadata, and storage keys"
    - "ZIP download includes video and audio files alongside images"
  artifacts:
    - path: "src/app/api/webhooks/n8n/route.ts"
      provides: "Extended webhook handler for video/audio asset persistence"
      contains: "videoAssets"
    - path: "src/lib/ai/video-pipeline.ts"
      provides: "Video/audio pipeline orchestrator with sequential generation and fallback"
      exports: ["runVideoPipeline"]
    - path: "src/app/api/campaigns/route.ts"
      provides: "Campaign creation with video pipeline integration"
      contains: "runVideoPipeline"
    - path: "src/lib/platforms/zip-packager.ts"
      provides: "ZIP packager extended to include video/audio files"
      contains: "video"
  key_links:
    - from: "src/lib/ai/video-pipeline.ts"
      to: "src/lib/ai/kling.ts"
      via: "import generateKlingVideo"
      pattern: "generateKlingVideo"
    - from: "src/lib/ai/video-pipeline.ts"
      to: "src/lib/ai/runway.ts"
      via: "import generateCinematicVideo"
      pattern: "generateCinematicVideo"
    - from: "src/lib/ai/video-pipeline.ts"
      to: "src/lib/ai/elevenlabs.ts"
      via: "import generateJapaneseVoiceover"
      pattern: "generateJapaneseVoiceover"
    - from: "src/lib/ai/video-pipeline.ts"
      to: "src/lib/ai/heygen.ts"
      via: "import generateAvatarVideo"
      pattern: "generateAvatarVideo"
    - from: "src/lib/ai/video-pipeline.ts"
      to: "src/lib/ai/provider-health.ts"
      via: "import providerHealth for fallback decisions"
      pattern: "providerHealth"
    - from: "src/app/api/webhooks/n8n/route.ts"
      to: "Supabase Storage"
      via: "download provider URL and upload to storage"
      pattern: "supabase\\.storage"
---

<objective>
Wire video and audio generation into the campaign pipeline with provider URL storage, webhook handler extension, fallback routing, and ZIP packaging.

Purpose: This is the core pipeline integration that makes video/audio generation actually work end-to-end. It orchestrates the four providers in the correct order (voiceover -> video ads -> cinematic -> avatar), downloads temporary provider URLs to Supabase Storage, persists asset records, and extends the existing ZIP packager to include video/audio files.

Output: Video pipeline orchestrator, extended webhook handler, extended ZIP packager
</objective>

<execution_context>
@/Users/hani/.claude/get-shit-done/workflows/execute-plan.md
@/Users/hani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-video-audio-pipeline/04-RESEARCH.md
@.planning/phases/04-video-audio-pipeline/04-01-SUMMARY.md
@src/app/api/webhooks/n8n/route.ts
@src/app/api/campaigns/route.ts
@src/lib/platforms/zip-packager.ts
@src/types/campaign.ts
@src/lib/db/schema.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create video pipeline orchestrator with fallback routing</name>
  <files>
    src/lib/ai/video-pipeline.ts
  </files>
  <action>
    Create `src/lib/ai/video-pipeline.ts` -- the main orchestrator that coordinates all video/audio generation for a campaign.

    Export `runVideoPipeline(params: VideoPipelineInput): Promise<VideoPipelineResult>`:

    **Input type:**
    ```typescript
    interface VideoPipelineInput {
      campaignId: string
      brief: CampaignBrief        // from campaign.brief
      copyText: string             // A-case headline + body for voiceover script
      compositedImageUrls: string[] // composited images to use as video input
      platforms: string[]          // from brief, to determine aspect ratios needed
      updateProgress: (update: Partial<CampaignProgress>) => Promise<void>
    }
    ```

    **Result type:**
    ```typescript
    interface VideoPipelineResult {
      voiceover: { buffer: Buffer, durationEstimate: number } | null
      videos: Array<{ url: string, provider: string, aspectRatio: string, duration: number, type: "ad" | "cinematic" }>
      avatarVideo: { url: string, provider: string, duration: number } | null
      errors: Array<{ stage: string, provider: string, message: string }>
    }
    ```

    **Pipeline logic (sequential, cheapest first per research):**

    1. **Determine what to generate:**
       - Import `PLATFORM_ASPECT_RATIOS` from video-providers.ts
       - Map `platforms` to required aspect ratios, deduplicate
       - If no video-capable platforms selected, return early with all statuses "skipped"

    2. **Step 1: Voiceover (ElevenLabs, ~$0.05):**
       - `await updateProgress({ voiceoverStatus: "generating", currentStep: "ナレーション生成中..." })`
       - Use dynamic import: `const { generateJapaneseVoiceover } = await import("@/lib/ai/elevenlabs")`
       - Call with `copyText` and `process.env.ELEVENLABS_VOICE_ID_JP_FEMALE` (default female voice)
       - On success: `await updateProgress({ voiceoverStatus: "complete" })`
       - On failure: log error, set voiceoverStatus to "failed". **Continue** -- voiceover failure should NOT halt video generation (videos can be silent). But DO skip avatar step (avatar needs voiceover).
       - Import `providerHealth` and call `recordSuccess/recordFailure` accordingly.

    3. **Step 2: Video ads (Kling via fal.ai, ~$0.70 each):**
       - `await updateProgress({ videoStatus: "generating", currentStep: "動画広告生成中..." })`
       - For each unique aspect ratio needed:
         - Use first composited image as source (image-to-video)
         - Check `providerHealth.shouldUseProvider("kling")`
         - If healthy: call `generateKlingVideo` with prompt from brief's creative direction, imageUrl, aspectRatio, duration: 10
         - If Kling fails OR circuit open: fallback to Runway via `FALLBACK_MAP`
           - Call `generateCinematicVideo` with same image and ratio mapped to Runway format ("16:9" -> "1920:1080", "9:16" -> "1080:1920", "1:1" -> "960:960")
         - Generate aspect ratios **sequentially** (not parallel) per research anti-pattern guidance
       - Record each video in the results array with provider, aspect ratio, duration, type: "ad"

    4. **Step 3: Cinematic video (Runway Gen-4, ~$0.50):**
       - Only if at least one composited image exists
       - Check `providerHealth.shouldUseProvider("runway")`
       - Call `generateCinematicVideo` with first composited image, cinematic-style prompt, ratio "1920:1080", duration 10
       - If Runway fails: fallback to Kling with "16:9" aspect ratio
       - Record in results with type: "cinematic"

    5. **Step 4: Avatar video (HeyGen, ~$1.00+):**
       - Only if voiceover succeeded (avatar needs voiceover for lip-sync)
       - `await updateProgress({ avatarStatus: "generating", currentStep: "アバター動画生成中..." })`
       - Call `generateAvatarVideo` with `process.env.HEYGEN_DEFAULT_AVATAR_ID`, `process.env.HEYGEN_JP_VOICE_ID`, copyText as script, dimension { width: 1080, height: 1920 } for 9:16
       - No fallback for HeyGen (unique capability per research)
       - On failure: set avatarStatus to "failed", log error, continue

    6. **Final status update:**
       - Calculate overall videoStatus based on individual results
       - `await updateProgress({ videoStatus: hasAnyVideo ? "complete" : "failed", avatarStatus: avatarResult ? "complete" : voiceoverFailed ? "skipped" : "failed" })`

    **Error handling throughout:**
    - Each step wrapped in try/catch
    - Errors collected in `errors` array, not thrown
    - Pipeline continues on individual step failure (non-fatal, matching Phase 2-3 pattern)
    - Log each error with `console.error("Video pipeline [stage] failed:", error)`

    **Key design decision:** This orchestrator is designed to be called from BOTH the direct generation fallback path (in campaigns/route.ts) AND from the n8n webhook handler. When called from n8n, the n8n workflow can invoke individual providers directly via HTTP Request nodes, but this orchestrator provides the full pipeline for the direct fallback path.
  </action>
  <verify>
    `pnpm build` passes. `src/lib/ai/video-pipeline.ts` exports `runVideoPipeline`. Grep confirms imports from all 4 provider modules and provider-health.
  </verify>
  <done>
    Video pipeline orchestrator created with sequential generation order (voiceover -> video ads -> cinematic -> avatar), per-step fallback routing using provider health circuit breaker, non-fatal error collection, and progressive status updates.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend webhook handler, campaign pipeline, and ZIP packager for video/audio</name>
  <files>
    src/app/api/webhooks/n8n/route.ts
    src/app/api/campaigns/route.ts
    src/lib/platforms/zip-packager.ts
  </files>
  <action>
    **1. Extend n8n webhook handler (`src/app/api/webhooks/n8n/route.ts`):**

    Add video/audio asset handling to the existing webhook callback:

    a. Extend `N8nWebhookPayload` interface with:
       ```typescript
       videoAssets?: Array<{
         url: string
         provider: "kling" | "runway" | "heygen"
         aspectRatio: string
         duration: number
         type: "ad" | "cinematic" | "avatar"
         mimeType: string
       }>
       audioAssets?: Array<{
         url: string
         provider: "elevenlabs"
         duration: number
         mimeType: string
         voiceId: string
       }>
       stage?: "copy" | "image" | "voiceover" | "video" | "avatar" | "complete"
       ```

    b. Add a utility function `downloadToStorage(url: string, bucket: string, path: string): Promise<string>`:
       - Import `createClient` from `@/lib/supabase/admin` (use admin client for server-side storage operations)
       - Fetch the URL, get the response as arrayBuffer
       - Upload to Supabase Storage: `supabase.storage.from(bucket).upload(path, buffer, { contentType: mimeType })`
       - Return the storage path (not the full URL)
       - This is CRITICAL per research: provider URLs are temporary and expire. Must download immediately.

    c. After existing image/compositing handling, add video/audio asset processing:
       - For each `videoAsset` in payload:
         - Download to Supabase Storage via `downloadToStorage(url, "campaign-videos", "campaigns/${campaignId}/videos/${provider}-${aspectRatio}-${Date.now()}.mp4")`
         - Insert into assets table: `{ campaignId, type: "video", storageKey, fileName, width/height from aspect ratio, mimeType, modelUsed: provider, metadata: { provider, aspectRatio, duration, videoType: type } }`
       - For each `audioAsset` in payload:
         - Download to Supabase Storage: `downloadToStorage(url, "campaign-audio", "campaigns/${campaignId}/audio/${provider}-${Date.now()}.mp3")`
         - Insert into assets table: `{ campaignId, type: "audio", storageKey, fileName, mimeType: "audio/mpeg", modelUsed: provider, metadata: { provider, duration, voiceId } }`

    d. Update progress with stage-specific JSONB merge (not full replacement) to avoid race conditions:
       - When `stage === "voiceover"`: update only voiceoverStatus
       - When `stage === "video"`: update only videoStatus
       - When `stage === "avatar"`: update only avatarStatus
       - Use SQL pattern: read current progress, merge new fields, write back
       - This prevents the race condition described in research Pitfall 6

    e. Update final completion progress to include all video/audio statuses.

    **2. Extend campaign pipeline (`src/app/api/campaigns/route.ts`):**

    In the `runDirectGeneration` function (the fallback path when n8n is not configured):

    a. After the existing platform resize and email stages, add video pipeline stage:
       ```typescript
       // Stage 6: Video/Audio pipeline
       if (/* campaign has video-capable platforms */) {
         const { runVideoPipeline } = await import("@/lib/ai/video-pipeline")
         const videoResult = await runVideoPipeline({
           campaignId,
           brief: campaignBrief,
           copyText: firstVariant.headline + " " + firstVariant.bodyText,
           compositedImageUrls: compositedImages.map(a => a.storageKey),
           platforms: campaignBrief.platforms,
           updateProgress: async (update) => {
             const current = await db.select({ progress: campaigns.progress }).from(campaigns).where(eq(campaigns.id, campaignId)).limit(1)
             await db.update(campaigns).set({
               progress: { ...current[0]?.progress, ...update }
             }).where(eq(campaigns.id, campaignId))
           }
         })

         // Download video URLs to Supabase Storage and create asset records
         for (const video of videoResult.videos) {
           const storagePath = `campaigns/${campaignId}/videos/${video.provider}-${video.aspectRatio.replace(":", "x")}-${Date.now()}.mp4`
           const storageKey = await downloadToStorage(video.url, "campaign-videos", storagePath)
           await db.insert(assets).values({
             campaignId,
             type: "video",
             storageKey,
             fileName: `${video.type}-${video.aspectRatio.replace(":", "x")}.mp4`,
             mimeType: "video/mp4",
             modelUsed: video.provider,
             metadata: { provider: video.provider, aspectRatio: video.aspectRatio, duration: video.duration, videoType: video.type },
           })
         }

         // Upload voiceover buffer to Supabase Storage
         if (videoResult.voiceover) {
           // Upload buffer directly to storage
           const audioPath = `campaigns/${campaignId}/audio/voiceover-${Date.now()}.mp3`
           // Use admin supabase client to upload buffer
           await db.insert(assets).values({
             campaignId,
             type: "audio",
             storageKey: audioPath,
             fileName: "voiceover.mp3",
             mimeType: "audio/mpeg",
             modelUsed: "elevenlabs",
             metadata: { provider: "elevenlabs", duration: videoResult.voiceover.durationEstimate },
           })
         }

         // Handle avatar video similarly
       }
       ```

    b. Move/extract the `downloadToStorage` function to be shared between webhook handler and campaign route. Place it as a helper at the top of the webhook handler file or in a shared utility. For simplicity, define it in both files using the same implementation (DRY is less important than keeping the plan scope manageable).

    c. Update the final completion progress to include video/audio statuses.

    **3. Extend ZIP packager (`src/lib/platforms/zip-packager.ts`):**

    a. In the `buildCampaignZip` function, after adding image assets to the ZIP:
       - Query video assets: `db.select().from(assets).where(and(eq(assets.campaignId, campaignId), eq(assets.type, "video")))`
       - Query audio assets: `db.select().from(assets).where(and(eq(assets.campaignId, campaignId), eq(assets.type, "audio")))`
       - Add video files to ZIP under `videos/` folder, organized by aspect ratio
       - Add audio files to ZIP under `audio/` folder
       - Fetch video/audio from Supabase Storage using the storageKey (same batched fetch pattern as images)

    b. Create Supabase Storage buckets note: add `campaign-videos` and `campaign-audio` to the pending todos in STATE.md (these need to be created manually in Supabase dashboard with public: true).
  </action>
  <verify>
    `pnpm build` passes. Webhook handler has `videoAssets` and `audioAssets` in its payload type. `runVideoPipeline` is imported in campaigns/route.ts. ZIP packager includes video/audio query logic. Grep for "downloadToStorage" in both route files.
  </verify>
  <done>
    Webhook handler extended to persist video/audio assets with Supabase Storage download. Campaign direct generation fallback includes video pipeline stage. ZIP packager includes video and audio files in download. Provider URLs are immediately downloaded to prevent expiry.
  </done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with no type errors
2. Webhook handler processes videoAssets and audioAssets payloads
3. Provider URLs downloaded to Supabase Storage before storing (never store provider URLs directly)
4. Campaign creation triggers video pipeline after image/compositing stages
5. ZIP download includes videos/ and audio/ folders
6. Progress updates use merge pattern (not full replacement) to avoid race conditions
7. Video pipeline follows correct generation order: voiceover -> video ads -> cinematic -> avatar
</verification>

<success_criteria>
- End-to-end: campaign creation with video-capable platforms triggers voiceover, video ad, cinematic, and avatar generation
- Provider URLs downloaded to Supabase Storage immediately (never stored directly)
- Fallback routing activates when primary provider fails
- ZIP download includes all asset types (images, videos, audio)
- Non-fatal pattern: video failures don't prevent campaign completion
</success_criteria>

<output>
After completion, create `.planning/phases/04-video-audio-pipeline/04-02-SUMMARY.md`
</output>
