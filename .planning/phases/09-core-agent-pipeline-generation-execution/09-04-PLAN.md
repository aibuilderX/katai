---
phase: 09-core-agent-pipeline-generation-execution
plan: 04
type: execute
wave: 4
depends_on: [09-03]
files_modified:
  - src/app/api/internal/composite/route.ts
  - src/app/api/internal/resize/route.ts
autonomous: true
requirements: [GENX-01, GENX-02, GENX-06]

must_haves:
  truths:
    - "Flux image generation sub-workflow calls fal.ai queue API for each Art Director image prompt, polls for completion, and collects generated image URLs"
    - "JP text compositing runs via an internal Next.js API endpoint that wraps the existing compositeCampaignImages function with HMAC authentication"
    - "Platform resize runs via an internal Next.js API endpoint that wraps the existing resizeForPlatforms function with HMAC authentication"
    - "Generated images are stored in Supabase Storage and asset records are created in the database"
  artifacts:
    - path: "src/app/api/internal/composite/route.ts"
      provides: "Internal API for JP text compositing called by n8n"
      contains: "compositeCampaignImages"
    - path: "src/app/api/internal/resize/route.ts"
      provides: "Internal API for platform-specific image resizing called by n8n"
      contains: "resizeForPlatforms"
    - path: "n8n sub-workflow: Flux Image Generation"
      provides: "Image generation from Art Director prompts via fal.ai"
      contains: "fal.ai queue API"
    - path: "n8n sub-workflow: Compositing + Resize"
      provides: "JP text overlay and platform resize via internal APIs"
      contains: "internal/composite"
  key_links:
    - from: "n8n Flux sub-workflow"
      to: "fal.ai API"
      via: "HTTP Request with queue submit + poll + retrieve pattern"
      pattern: "queue.fal.run/fal-ai/flux-pro"
    - from: "n8n Compositing sub-workflow"
      to: "src/app/api/internal/composite/route.ts"
      via: "HTTP POST with HMAC authentication"
      pattern: "internal/composite"
    - from: "n8n Resize sub-workflow"
      to: "src/app/api/internal/resize/route.ts"
      via: "HTTP POST with HMAC authentication"
      pattern: "internal/resize"
---

<objective>
Create internal Next.js API endpoints for compositing and resize, plus n8n sub-workflows for Flux image generation, JP text compositing, and platform resize.

Purpose: These sub-workflows generate the visual assets of the campaign -- AI-generated images from Art Director prompts, Japanese text overlay via compositing, and platform-specific resizing. Using internal API endpoints for compositing/resize reuses the battle-tested TypeScript code with its Sharp + node-canvas + BudouX dependencies.

Output: 2 new internal API endpoints (composite, resize), n8n sub-workflows for Flux image gen and compositing+resize, master orchestrator updated with real sub-workflow IDs.
</objective>

<execution_context>
@/Users/hani/.claude/get-shit-done/workflows/execute-plan.md
@/Users/hani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-CONTEXT.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-RESEARCH.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-01-SUMMARY.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-03-SUMMARY.md
@src/lib/compositing/index.ts
@src/lib/platforms/image-resizer.ts
@src/lib/ai/flux.ts
@src/app/api/webhooks/n8n/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create internal API endpoints for compositing and resize</name>
  <files>
    src/app/api/internal/composite/route.ts
    src/app/api/internal/resize/route.ts
  </files>
  <action>
**Security pattern:** Both internal endpoints verify the same HMAC-SHA256 signature as the n8n callback handler. Read `N8N_WEBHOOK_SECRET` from env, compute HMAC of request body, compare with `X-Signature` header. This prevents unauthorized access while allowing n8n to call these endpoints.

**1. Create `src/app/api/internal/composite/route.ts`:**

```typescript
import { NextResponse } from "next/server"
import crypto from "crypto"
import { db } from "@/lib/db"
import { campaigns, copyVariants, assets, brandProfiles } from "@/lib/db/schema"
import { eq, and } from "drizzle-orm"

export const maxDuration = 120  // Compositing can take time for multiple images

function verifySignature(body: string, signature: string): boolean {
  const secret = process.env.N8N_WEBHOOK_SECRET
  if (!secret) return false
  const expected = crypto.createHmac("sha256", secret).update(body).digest("hex")
  try {
    return crypto.timingSafeEqual(Buffer.from(signature, "hex"), Buffer.from(expected, "hex"))
  } catch { return false }
}

export async function POST(request: Request) {
  const rawBody = await request.text()
  const signature = request.headers.get("X-Signature")
  if (!signature || !verifySignature(rawBody, signature)) {
    return NextResponse.json({ error: "Unauthorized" }, { status: 401 })
  }

  const payload = JSON.parse(rawBody)
  // Expected: { campaignId, imageUrls: string[], copyVariantLabel?: string }
  const { campaignId, imageUrls, copyVariantLabel = "A案" } = payload

  // Fetch campaign brand profile
  const campaignRow = await db.select({ brandProfileId: campaigns.brandProfileId })
    .from(campaigns).where(eq(campaigns.id, campaignId)).limit(1)
  if (campaignRow.length === 0) {
    return NextResponse.json({ error: "Campaign not found" }, { status: 404 })
  }

  const brand = await db.select().from(brandProfiles)
    .where(eq(brandProfiles.id, campaignRow[0].brandProfileId)).limit(1)

  // Fetch copy variant for text overlay
  const variant = await db.select().from(copyVariants)
    .where(and(
      eq(copyVariants.campaignId, campaignId),
      eq(copyVariants.variantLabel, copyVariantLabel)
    )).limit(1)

  if (variant.length === 0 || brand.length === 0) {
    return NextResponse.json({ error: "Missing copy variant or brand profile" }, { status: 400 })
  }

  // Build base images array from provided URLs
  // First, create asset records for the base images if they don't exist
  const baseImages = imageUrls.map((url: string, i: number) => ({
    assetId: `temp-${i}`,  // Will be replaced with actual asset IDs
    url,
    width: 1024,
    height: 1024,
  }))

  try {
    const { compositeCampaignImages } = await import("@/lib/compositing")
    const result = await compositeCampaignImages({
      campaignId,
      baseImages,
      copyVariant: {
        headline: variant[0].headline,
        bodyText: variant[0].bodyText,
        ctaText: variant[0].ctaText,
      },
      brandProfile: {
        fontPreference: brand[0].fontPreference ?? "noto_sans_jp",
        colors: brand[0].colors,
        logoUrl: brand[0].logoUrl,
      },
    })

    return NextResponse.json({ success: true, compositedImages: result })
  } catch (error) {
    console.error("[internal/composite] Compositing failed:", error)
    return NextResponse.json({
      error: "Compositing failed",
      details: error instanceof Error ? error.message : "Unknown error"
    }, { status: 500 })
  }
}
```

Adapt the compositing call to work with the actual `compositeCampaignImages` function signature. The function already handles asset creation internally. Ensure the response returns composited image URLs/storage keys so n8n can track them.

**2. Create `src/app/api/internal/resize/route.ts`:**

Same HMAC verification pattern. Accepts:
```json
{
  "campaignId": "...",
  "platforms": ["instagram", "line", "x"],
  "sourceImageUrls": ["url1", "url2"]
}
```

The endpoint:
1. Downloads each source image URL to a buffer
2. Calls `getResizeTargetsForPlatforms(platforms)` to get resize specs
3. Calls `resizeForPlatforms(buffer, width, height, targets, bgColor)` for each source
4. Uploads resized images to Supabase Storage `platform-images` bucket
5. Creates `platform_image` asset records in the database
6. Returns the list of created platform image URLs

Use the exact resize logic from the existing `runDirectGeneration` function in `src/app/api/campaigns/route.ts` (stages 4), adapted into this standalone endpoint.

Set `maxDuration = 120` for potentially processing multiple images across multiple platforms.

  </action>
  <verify>
Run `npx tsc --noEmit` -- both endpoints compile clean. Test: `curl -X POST /api/internal/composite -H "X-Signature: test"` should return 401 (invalid signature). Code structure matches existing patterns in the webhook callback handler.
  </verify>
  <done>
Internal composite endpoint wraps existing compositeCampaignImages with HMAC auth. Internal resize endpoint wraps existing resizeForPlatforms with HMAC auth, uploads to Supabase Storage, creates asset records. Both endpoints are secured and return structured responses for n8n consumption.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Flux image generation and compositing+resize sub-workflows in n8n</name>
  <files>
    (n8n workflows via MCP tools)
  </files>
  <action>
**Part A: Flux Image Generation Sub-Workflow**

Create via `mcp__n8n-mcp__n8n_create_workflow`.

1. **Execute Workflow Trigger** -- receives pipeline data with `pipelineState.artDirector.imagePrompts`

2. **Progress Callback: Asset Generation Active**
   - POST: `{ agentStep: { agentName: "asset_generation", labelJa: "アセット生成中", status: "active", startedAt } }`

3. **Loop Over Image Prompts (Code node + Loop):**
   For each imagePrompt in `artDirector.imagePrompts`:

   a. **Submit to fal.ai Queue (HTTP Request):**
      - POST `https://queue.fal.run/fal-ai/flux-pro/v1.1-ultra`
      - Headers: `Authorization: Key ${FAL_KEY}`
      - Body:
        ```json
        {
          "prompt": "{{ imagePrompt.prompt }}",
          "num_images": 1,
          "enable_safety_checker": true,
          "image_size": "{{ mapAspectRatioToFalSize(imagePrompt.aspectRatio) }}"
        }
        ```
      - `mapAspectRatioToFalSize`: "1:1" -> "square_hd", "16:9" -> "landscape_16_9", "9:16" -> "portrait_16_9", "4:5" -> { width: 1080, height: 1350 }
      - Response: `{ request_id: "..." }`

   b. **Poll for Completion (HTTP Request in Loop):**
      - GET `https://queue.fal.run/fal-ai/flux-pro/v1.1-ultra/requests/{{ request_id }}/status`
      - Loop with Wait node (5 second delay) until status is "COMPLETED"
      - Max polls: 60 (5 minutes timeout)

   c. **Retrieve Result (HTTP Request):**
      - GET `https://queue.fal.run/fal-ai/flux-pro/v1.1-ultra/requests/{{ request_id }}`
      - Extract: `images[0].url`

   d. **Create Asset Record (HTTP Request to internal API or direct DB):**
      - Since n8n cannot directly write to Supabase DB with the app's schema, the simplest approach is to collect all image URLs and pass them to the compositing sub-workflow, which will handle asset creation via the internal API.

4. **Collect all generated image URLs into an array**

5. **Cost entry:** For each fal.ai call, estimate cost based on image size (Flux 1.1 Pro Ultra pricing: ~$0.06/image -> ~9 yen/image)

6. **Return:** pipelineState + array of generated image URLs

**Error handling per image:**
- If a specific image fails: log error, continue with remaining prompts
- If ALL images fail: mark as failed, pipeline continues (non-fatal)
- Circuit breaker: not needed here since we're calling fal.ai directly from n8n (the existing ProviderHealthTracker is for the Next.js server). Add a simple try/catch per image.

**Part B: Compositing + Resize Sub-Workflow**

Create via `mcp__n8n-mcp__n8n_create_workflow`.

1. **Execute Workflow Trigger** -- receives pipeline data + generated image URLs

2. **Call Internal Composite API (HTTP Request):**
   - POST to `{{ NEXT_JS_URL }}/api/internal/composite`
   - Headers: `X-Signature: {{ computed HMAC }}`
   - Body: `{ campaignId, imageUrls: [generated image URLs], copyVariantLabel: "A案" }`
   - Timeout: 120000ms
   - On error: continue (compositing is non-fatal, base images still available)

3. **Call Internal Resize API (HTTP Request):**
   - POST to `{{ NEXT_JS_URL }}/api/internal/resize`
   - Headers: `X-Signature: {{ computed HMAC }}`
   - Body: `{ campaignId, platforms: brief.platforms, sourceImageUrls: [composited image URLs or base image URLs if compositing failed] }`
   - Timeout: 120000ms
   - On error: continue (resize is non-fatal)

4. **Progress callback:** Asset generation complete
   - `{ agentStep: { agentName: "asset_generation", status: "complete", summaryJa: "画像{N}枚+合成+リサイズ完了", completedAt } }`

5. **Cost entries:** compositing and resize are server-side operations, not billed API calls. Include fal.ai costs from the Flux step.

**Part C: Wire into Master Orchestrator**

Update the master orchestrator to:
1. After the Copywriter/Art Director merge, dispatch to Flux Image Generation sub-workflow
2. After Flux completes, dispatch to Compositing + Resize sub-workflow
3. After Compositing + Resize completes, send the "campaign complete" callback (copy + images ready)
4. Then fork async for video pipeline (plan 09-05)

  </action>
  <verify>
Flux sub-workflow submits to fal.ai queue, polls for completion, retrieves image URLs. Compositing sub-workflow calls internal API endpoint. Resize sub-workflow calls internal API endpoint. Master orchestrator dispatches in correct order: agents -> Flux -> compositing -> resize -> complete callback. All workflows validate clean.
  </verify>
  <done>
Flux image generation sub-workflow calls fal.ai queue API for each Art Director prompt with correct aspect ratio mapping, polls for completion, and collects URLs. Compositing sub-workflow calls internal Next.js endpoint with HMAC auth. Resize sub-workflow calls internal Next.js endpoint. Master orchestrator routes correctly through the generation chain. All failures are non-fatal (images still available without compositing, composited images still available without resize).
  </done>
</task>

</tasks>

<verification>
1. Internal composite API endpoint exists at /api/internal/composite with HMAC auth
2. Internal resize API endpoint exists at /api/internal/resize with HMAC auth
3. Flux sub-workflow submits to fal.ai, polls, retrieves -- handles per-image failures gracefully
4. Compositing sub-workflow calls internal API with correct payload shape
5. Resize sub-workflow calls internal API with correct platforms and image URLs
6. Master orchestrator dispatches generation sub-workflows in correct sequence
7. All generation failures are non-fatal -- pipeline continues with available assets
</verification>

<success_criteria>
- Flux 1.1 Pro Ultra generates images from Art Director prompts via fal.ai async queue
- JP text compositing runs via internal API reusing existing Sharp + node-canvas + BudouX code
- Platform resize runs via internal API reusing existing resizer code
- All generated assets are stored in Supabase Storage with asset records
- Any single generation failure does not block the rest of the pipeline
</success_criteria>

<output>
After completion, create `.planning/phases/09-core-agent-pipeline-generation-execution/09-04-SUMMARY.md`
</output>
