---
phase: 09-core-agent-pipeline-generation-execution
plan: 05
type: execute
wave: 5
depends_on: [09-04]
files_modified:
  - src/app/api/internal/video-pipeline/route.ts
  - src/app/api/campaigns/[id]/download/route.ts
autonomous: false
requirements: [GENX-03, GENX-04, GENX-05, GENX-07, GENX-08]

must_haves:
  truths:
    - "Video pipeline sub-workflow triggers asynchronously after campaign marks complete (copy+images delivered first, video arrives later via Realtime)"
    - "Video pipeline calls internal Next.js API endpoint that wraps the existing runVideoPipeline function with circuit breaker"
    - "ZIP download endpoint exists and produces a downloadable ZIP organized by platform with all campaign assets"
    - "Any single AI provider failure in the video pipeline does not block the campaign -- copy and images are already delivered"
    - "Campaign with no video-capable platforms skips the video pipeline entirely"
  artifacts:
    - path: "src/app/api/internal/video-pipeline/route.ts"
      provides: "Internal API for video/audio/avatar generation called by n8n"
      contains: "runVideoPipeline"
    - path: "src/app/api/campaigns/[id]/download/route.ts"
      provides: "ZIP download endpoint with platform-organized assets"
      contains: "buildCampaignZip"
    - path: "n8n sub-workflow: Video Pipeline"
      provides: "Async video generation triggered after campaign complete"
      contains: "internal/video-pipeline"
  key_links:
    - from: "Master Orchestrator async fork"
      to: "n8n Video Pipeline sub-workflow"
      via: "Execute Sub-workflow with waitForSubWorkflow: false"
      pattern: "video-pipeline"
    - from: "n8n Video Pipeline sub-workflow"
      to: "src/app/api/internal/video-pipeline/route.ts"
      via: "HTTP POST with HMAC authentication"
      pattern: "internal/video-pipeline"
    - from: "src/app/api/campaigns/[id]/download/route.ts"
      to: "buildCampaignZip"
      via: "Direct function call on user download request"
      pattern: "buildCampaignZip"
    - from: "Master Orchestrator success callback (step 13)"
      to: "src/app/api/webhooks/n8n/route.ts copyVariants handler"
      via: "copyVariants top-level field in success callback payload"
      pattern: "copyVariants.*insert"
---

<objective>
Create the video pipeline internal API endpoint and n8n sub-workflow for async video/audio/avatar generation, verify/create the ZIP download endpoint, and wire the async video fork into the master orchestrator. Conclude with a human verification checkpoint to test the complete pipeline end-to-end.

Purpose: This plan completes the generation chain. Video is delivered asynchronously after the main campaign (copy + images) marks complete, ensuring fast initial delivery. The ZIP endpoint provides the final downloadable output organized by platform.

Output: Internal video pipeline API endpoint, n8n video sub-workflow, verified ZIP download endpoint, complete master orchestrator with all sub-workflows wired, end-to-end checkpoint.
</objective>

<execution_context>
@/Users/hani/.claude/get-shit-done/workflows/execute-plan.md
@/Users/hani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-CONTEXT.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-RESEARCH.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-01-SUMMARY.md
@.planning/phases/09-core-agent-pipeline-generation-execution/09-04-SUMMARY.md
@src/lib/ai/video-pipeline.ts
@src/lib/ai/provider-health.ts
@src/lib/platforms/zip-packager.ts
@src/app/api/campaigns/[id]/download/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create video pipeline internal API and n8n sub-workflow, verify ZIP endpoint</name>
  <files>
    src/app/api/internal/video-pipeline/route.ts
    src/app/api/campaigns/[id]/download/route.ts
  </files>
  <action>
**Part A: Create `src/app/api/internal/video-pipeline/route.ts`**

Same HMAC verification pattern as the composite/resize internal endpoints.

```typescript
import { NextResponse } from "next/server"
import crypto from "crypto"
import { db } from "@/lib/db"
import { campaigns, copyVariants, assets } from "@/lib/db/schema"
import { eq, and } from "drizzle-orm"

export const maxDuration = 300  // Video generation can take 5+ minutes

function verifySignature(body: string, signature: string): boolean {
  // Same HMAC verification as other internal endpoints
}

export async function POST(request: Request) {
  // HMAC verification
  // Parse payload: { campaignId, platforms, callbackUrl, webhookSecret }

  const { campaignId, platforms, callbackUrl, webhookSecret } = payload

  // Fetch campaign data
  const campaign = await db.select().from(campaigns).where(eq(campaigns.id, campaignId)).limit(1)
  if (campaign.length === 0) {
    return NextResponse.json({ error: "Campaign not found" }, { status: 404 })
  }

  const brief = campaign[0].brief as CampaignBrief

  // Check if any selected platform has video aspect ratios
  const { PLATFORM_ASPECT_RATIOS } = await import("@/lib/constants/video-providers")
  const hasVideoPlatforms = platforms.some((p: string) => PLATFORM_ASPECT_RATIOS[p])

  if (!hasVideoPlatforms) {
    return NextResponse.json({ success: true, skipped: true, reason: "No video-capable platforms" })
  }

  // Fetch copy variant and composited images
  const firstVariant = await db.select().from(copyVariants)
    .where(and(eq(copyVariants.campaignId, campaignId), eq(copyVariants.variantLabel, "A案")))
    .limit(1)

  const compositedAssets = await db.select().from(assets)
    .where(and(eq(assets.campaignId, campaignId), eq(assets.type, "composited_image")))

  const compositedImageUrls = compositedAssets.length > 0
    ? compositedAssets.map(a => a.storageKey)
    : []  // Fall back to base images if no composited

  const copyText = firstVariant.length > 0
    ? `${firstVariant[0].headline} ${firstVariant[0].bodyText}`
    : brief.objective

  // Run the existing video pipeline
  // This uses the ProviderHealthTracker circuit breaker automatically (GENX-08)
  try {
    const { runVideoPipeline } = await import("@/lib/ai/video-pipeline")
    const { adminClient } = await import("@/lib/supabase/admin")

    const result = await runVideoPipeline({
      campaignId,
      brief,
      copyText,
      compositedImageUrls,
      platforms,
      updateProgress: async (update) => {
        // Send progress back to n8n callback
        // Merge into campaign progress via DB update
        const current = await db.select({ progress: campaigns.progress }).from(campaigns)
          .where(eq(campaigns.id, campaignId)).limit(1)
        const existing = (current[0]?.progress ?? {}) as Record<string, unknown>
        await db.update(campaigns).set({
          progress: { ...existing, ...update } as any,
        }).where(eq(campaigns.id, campaignId))
      },
    })

    // Download and persist video assets to Supabase Storage
    // (Replicate the logic from runDirectGeneration's video stage)
    for (const video of result.videos) {
      try {
        const storagePath = `campaigns/${campaignId}/videos/${video.provider}-${video.aspectRatio.replace(":", "x")}-${Date.now()}.mp4`
        const response = await fetch(video.url)
        if (!response.ok) continue
        const buffer = Buffer.from(await response.arrayBuffer())

        const { error } = await adminClient.storage.from("campaign-videos")
          .upload(storagePath, buffer, { contentType: "video/mp4", upsert: true })
        if (error) continue

        const [w, h] = video.aspectRatio.split(":").map(Number)
        const baseSize = 1080
        const width = w > h ? baseSize : Math.round(baseSize * (w / h))
        const height = h > w ? baseSize : Math.round(baseSize * (h / w))

        await db.insert(assets).values({
          campaignId, type: "video", storageKey: storagePath,
          fileName: `${video.type}-${video.aspectRatio.replace(":", "x")}.mp4`,
          width: String(width), height: String(height),
          mimeType: "video/mp4", modelUsed: video.provider,
          metadata: { provider: video.provider, aspectRatio: video.aspectRatio, duration: video.duration, videoType: video.type },
        })
      } catch (e) {
        console.error(`[video-pipeline] Failed to persist video:`, e)
      }
    }

    // Persist voiceover
    if (result.voiceover) {
      try {
        const audioPath = `campaigns/${campaignId}/audio/voiceover-${Date.now()}.mp3`
        const { error } = await adminClient.storage.from("campaign-audio")
          .upload(audioPath, result.voiceover.buffer, { contentType: "audio/mpeg", upsert: true })
        if (!error) {
          await db.insert(assets).values({
            campaignId, type: "audio", storageKey: audioPath,
            fileName: "voiceover.mp3", mimeType: "audio/mpeg", modelUsed: "elevenlabs",
            metadata: { provider: "elevenlabs", duration: result.voiceover.durationEstimate },
          })
        }
      } catch (e) { console.error("[video-pipeline] Audio persist failed:", e) }
    }

    // Persist avatar video
    if (result.avatarVideo) {
      try {
        const avatarPath = `campaigns/${campaignId}/videos/avatar-${Date.now()}.mp4`
        const resp = await fetch(result.avatarVideo.url)
        if (resp.ok) {
          const buf = Buffer.from(await resp.arrayBuffer())
          const { error } = await adminClient.storage.from("campaign-videos")
            .upload(avatarPath, buf, { contentType: "video/mp4", upsert: true })
          if (!error) {
            await db.insert(assets).values({
              campaignId, type: "video", storageKey: avatarPath,
              fileName: "avatar-9x16.mp4", width: "1080", height: "1920",
              mimeType: "video/mp4", modelUsed: result.avatarVideo.provider,
              metadata: { provider: result.avatarVideo.provider, aspectRatio: "9:16", duration: result.avatarVideo.duration, videoType: "avatar" },
            })
          }
        }
      } catch (e) { console.error("[video-pipeline] Avatar persist failed:", e) }
    }

    return NextResponse.json({
      success: true,
      videoCount: result.videos.length,
      hasVoiceover: !!result.voiceover,
      hasAvatar: !!result.avatarVideo,
    })
  } catch (error) {
    console.error("[internal/video-pipeline] Failed:", error)
    return NextResponse.json({
      error: "Video pipeline failed",
      details: error instanceof Error ? error.message : "Unknown"
    }, { status: 500 })
  }
}
```

**Part B: Verify/fix ZIP download endpoint**

Read the existing `src/app/api/campaigns/[id]/download/route.ts`. Verify it:
1. Accepts GET requests with the campaign ID
2. Calls `buildCampaignZip()` from `src/lib/platforms/zip-packager.ts`
3. Returns the ZIP as a downloadable file with correct Content-Type and Content-Disposition headers
4. Verifies user auth and team membership before allowing download

If the endpoint exists and is functional, no changes needed. If it's missing functionality (e.g., doesn't include composited images or platform-resized images), update it to query all asset types: `image`, `composited_image`, `platform_image`, `video`, `audio`, `email_html`.

**Part C: Create n8n Video Pipeline Sub-Workflow**

Create via `mcp__n8n-mcp__n8n_create_workflow`.

1. **Execute Workflow Trigger** -- receives campaign data

2. **Call Internal Video Pipeline API (HTTP Request):**
   - POST to `{{ NEXT_JS_URL }}/api/internal/video-pipeline`
   - Headers: `X-Signature: {{ computed HMAC }}`
   - Body: `{ campaignId, platforms: brief.platforms }`
   - Timeout: 300000ms (5 minutes -- video generation is slow)
   - On error: continue (video is non-fatal)

3. **Send Video Complete Callback (HTTP Request):**
   - If video succeeded: POST callback with `{ status: "progress", agentStep: { agentName: "asset_generation", status: "complete", summaryJa: "動画生成完了" } }`
   - If video failed: POST callback with error details (non-fatal, campaign already delivered)

**Part D: Wire Video Fork into Master Orchestrator**

Update the master orchestrator to:
1. After the compositing+resize completes, send the "campaign complete" callback to Next.js:
   - Explicit payload shape:
     ```json
     {
       "campaignId": "<id>",
       "status": "success",
       "pipelineState": "<full PipelineState object>",
       "pipelineVersion": "v1.1",
       "copyVariants": "<extracted from pipelineState.copywriter.variants, transformed to CopyVariantPayload[] shape>"
     }
     ```
   - **`copyVariants` MUST be a top-level field** (not nested inside pipelineState) because the existing webhook handler at `/api/webhooks/n8n/route.ts` reads `payload.copyVariants` and inserts them into the `copyVariants` relational table.
   - NOTE: The primary copyVariants persistence already happened in the master orchestrator step 9 (plan 09-01) before image generation. This inclusion in the success callback is a safety net ensuring the relational table is populated even if the intermediate callback was missed.
   - A Code node before the HTTP Request must extract and transform: `pipelineState.copywriter.variants.map(v => ({ platform: v.platform, variantLabel: v.variantLabel, headline: v.headline, bodyText: v.body, ctaText: v.cta, hashtags: v.hashtags, register: v.register }))`
   - This marks the campaign as "complete" in the DB -- user can now see copy + images
2. **After the success callback**, fork to the Video Pipeline sub-workflow with `waitForSubWorkflow: false` (async)
3. The video pipeline runs independently and sends its own callbacks as assets complete
4. If no video-capable platforms in brief.platforms, skip the video fork entirely (Code node check)

  </action>
  <verify>
Run `npx tsc --noEmit` -- video-pipeline endpoint and download endpoint compile clean. Video pipeline sub-workflow exists in n8n. Master orchestrator sends campaign-complete callback before video fork. ZIP download endpoint returns proper ZIP file.
  </verify>
  <done>
Internal video pipeline endpoint wraps existing runVideoPipeline with HMAC auth and circuit breaker. n8n video sub-workflow calls the endpoint asynchronously. ZIP download endpoint produces platform-organized ZIP. Master orchestrator sends campaign-complete (copy+images) before async video fork. All video failures are non-fatal.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: End-to-end pipeline verification</name>
  <files>
    (no files -- verification only)
  </files>
  <action>
This is a human verification checkpoint. No automated work -- the user verifies the complete pipeline end-to-end.

What was built across plans 09-01 through 09-05:
- Master orchestrator receiving webhook from Next.js
- Sequential dispatch: Strategic Insight -> Quality Gate -> Creative Director -> Parallel(Copywriter, Art Director) -> JP Localization -> Flux Image Gen -> Compositing -> Resize -> Complete Callback -> Async Video
- Per-agent progress reporting with Japanese labels and summaries
- Strategy accordion on campaign detail page
- ZIP download endpoint

Verification steps:

1. Set up n8n webhook URL: Add the n8n webhook URL (from the master orchestrator workflow's webhook node) to Next.js .env.local as N8N_WEBHOOK_URL. Ensure N8N_WEBHOOK_SECRET matches between Next.js and n8n.

2. Submit a test campaign: Go to the dashboard, create a campaign brief with at least 2 platforms (e.g., Instagram + LINE), select a brand profile, and submit.

3. Check per-agent progress: Watch the generation progress page -- verify:
   - "戦略分析中" with spinner, then checkmark with Japanese summary
   - "クリエイティブ設計中" with spinner, then checkmark
   - "コピーライティング中" and "アート設計中" appearing simultaneously (parallel)
   - "JP品質確認中" with possible revision indicator
   - "アセット生成中" for image generation/compositing

4. Check strategy accordion: After campaign completes, go to campaign detail page. Verify a collapsed "戦略的アプローチ" section appears between header and tab bar. Click to expand -- shows 2-3 lines of Japanese strategy. NO English framework names visible.

5. Check JP Localization: In the n8n execution log, verify the critique loop ran.

6. Check partial delivery: If any video generation failed, verify the campaign still shows as "complete" with copy + images available.

7. Test ZIP download: Click the download button -- verify ZIP contains files organized by platform.

8. No brand profile test: Create a minimal brand profile with no colors or tone tags. Submit a campaign. Verify images are generated with inferred visual direction (GENX-09).
  </action>
  <verify>User confirms the pipeline runs end-to-end or describes issues.</verify>
  <done>User types "approved" confirming: pipeline executes, progress shows per-agent steps, strategy accordion displays Japanese conclusions, ZIP downloads with platform-organized assets, partial delivery works on provider failure.</done>
</task>

</tasks>

<verification>
1. Video pipeline internal API exists with HMAC auth and circuit breaker via existing ProviderHealthTracker
2. Video runs asynchronously after campaign marks complete
3. ZIP download endpoint produces platform-organized ZIP
4. Master orchestrator sends campaign-complete callback before video fork
5. Campaign with no video platforms skips video entirely
6. End-to-end pipeline: brief submission -> all agents -> generation -> download works
</verification>

<success_criteria>
- Submitting a campaign brief triggers the full n8n pipeline end-to-end
- Per-agent progress indicators appear in real time with Japanese labels
- JP Localization critique loop can reject and request revisions
- Campaign completes with copy + images even if video fails
- ZIP download contains platform-organized assets
- No brand profile campaign produces images with inferred defaults
</success_criteria>

<output>
After completion, create `.planning/phases/09-core-agent-pipeline-generation-execution/09-05-SUMMARY.md`
</output>
